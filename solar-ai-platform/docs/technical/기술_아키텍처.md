# ì†”ë¼ìŠ¤ìº” ê¸°ìˆ  ì•„í‚¤í…ì²˜ ë¬¸ì„œ

## ğŸ“‘ ëª©ì°¨
1. [ì‹œìŠ¤í…œ ê°œìš”](#ì‹œìŠ¤í…œ-ê°œìš”)
2. [ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨](#ì•„í‚¤í…ì²˜-ë‹¤ì´ì–´ê·¸ë¨)
3. [ë°ì´í„° íŒŒì´í”„ë¼ì¸](#ë°ì´í„°-íŒŒì´í”„ë¼ì¸)
4. [AI ëª¨ë¸ ì„¤ê³„](#ai-ëª¨ë¸-ì„¤ê³„)
5. [API ì„¤ê³„](#api-ì„¤ê³„)
6. [í”„ë¡ íŠ¸ì—”ë“œ ì•„í‚¤í…ì²˜](#í”„ë¡ íŠ¸ì—”ë“œ-ì•„í‚¤í…ì²˜)
7. [ì¸í”„ë¼ ë° ë°°í¬](#ì¸í”„ë¼-ë°-ë°°í¬)
8. [ë³´ì•ˆ ë° ì„±ëŠ¥](#ë³´ì•ˆ-ë°-ì„±ëŠ¥)

---

## 1. ì‹œìŠ¤í…œ ê°œìš”

### 1.1 ê¸°ìˆ  ìŠ¤íƒ ìš”ì•½

```yaml
Frontend:
  Framework: Next.js 14 (App Router)
  Language: TypeScript 5.0+
  Styling: Tailwind CSS 3.4
  State Management: Zustand
  Maps: Kakao Maps API
  Charts: Recharts
  Forms: React Hook Form + Zod

Backend:
  Framework: FastAPI 0.104+
  Language: Python 3.11+
  Database: PostgreSQL 15 + PostGIS
  Cache: Redis 7.2
  Queue: Celery + RabbitMQ
  Storage: AWS S3

AI/ML:
  Training: Python, Jupyter
  Models: XGBoost, LightGBM, TensorFlow
  Computer Vision: OpenCV, Pillow, Rasterio
  Deployment: TensorFlow Serving, ONNX

Infrastructure:
  Cloud: AWS (EC2, RDS, S3, CloudFront)
  Frontend Hosting: Vercel
  Container: Docker, Docker Compose
  Orchestration: Kubernetes (ì„ íƒì )
  Monitoring: Sentry, CloudWatch, Grafana
  CI/CD: GitHub Actions
```

---

## 2. ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

### 2.1 ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Client Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   Web App   â”‚  â”‚  Mobile Web  â”‚  â”‚  Partner API  â”‚       â”‚
â”‚  â”‚  (Next.js)  â”‚  â”‚  (Responsive)â”‚  â”‚   (B2B)       â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   CDN (CloudFront) â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      API Gateway Layer                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              FastAPI Application                      â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â”‚  â”‚ Auth   â”‚  â”‚ Analysisâ”‚  â”‚ Payment  â”‚  â”‚ Report â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Serviceâ”‚  â”‚ Service â”‚  â”‚ Service  â”‚  â”‚ Serviceâ”‚ â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Cache     â”‚ â”‚  PostgreSQL â”‚ â”‚  Celery Queue  â”‚
â”‚  - Session       â”‚ â”‚  - User DB  â”‚ â”‚  - AI Tasks    â”‚
â”‚  - API Cache     â”‚ â”‚  - Analysis â”‚ â”‚  - Data Sync   â”‚
â”‚  - Rate Limit    â”‚ â”‚  - Geo Data â”‚ â”‚  - Reports     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AI/ML Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Solar Power  â”‚  â”‚ Roof Analysisâ”‚  â”‚ Cost         â”‚       â”‚
â”‚  â”‚ Prediction   â”‚  â”‚ (CV Model)   â”‚  â”‚ Optimization â”‚       â”‚
â”‚  â”‚ (XGBoost)    â”‚  â”‚              â”‚  â”‚              â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ê²½ê¸°ë„ ê¸°í›„      â”‚ â”‚ Kakao Maps  â”‚ â”‚  AWS S3        â”‚
â”‚ í”Œë«í¼ API       â”‚ â”‚ API         â”‚ â”‚  - Images      â”‚
â”‚ - ì¼ì‚¬ëŸ‰         â”‚ â”‚ - Satellite â”‚ â”‚  - Reports     â”‚
â”‚ - ê¸°ì˜¨/ìŠµë„      â”‚ â”‚ - Geocoding â”‚ â”‚  - Models      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ë°ì´í„° íë¦„

```
ì‚¬ìš©ì ìš”ì²­ (ì£¼ì†Œ ì…ë ¥)
    â†“
Next.js Frontend (ê²€ì¦)
    â†“
FastAPI Backend (API ì—”ë“œí¬ì¸íŠ¸)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Geocoding      â”‚ â†’ Kakao Maps API
â”‚    (ì£¼ì†Œ â†’ ì¢Œí‘œ)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. ìºì‹œ í™•ì¸      â”‚ â†’ Redis (ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“ (ì—†ìœ¼ë©´)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ë°ì´í„° ìˆ˜ì§‘    â”‚
â”‚    - ê¸°í›„ ë°ì´í„°  â”‚ â†’ ê²½ê¸°ë„ ê¸°í›„í”Œë«í¼
â”‚    - ìœ„ì„± ì´ë¯¸ì§€  â”‚ â†’ Kakao Maps
â”‚    - ì „ê¸°ìš”ê¸ˆ     â”‚ â†’ DB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. AI ë¶„ì„ (ë¹„ë™ê¸°)â”‚
â”‚    - ì§€ë¶• ë¶„ì„    â”‚ â†’ CV Model (Celery Task)
â”‚    - ë°œì „ëŸ‰ ì˜ˆì¸¡  â”‚ â†’ XGBoost Model
â”‚    - ë¹„ìš© ê³„ì‚°    â”‚ â†’ Cost Engine
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. ê²°ê³¼ ì €ì¥      â”‚ â†’ PostgreSQL + Redis
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. ì‘ë‹µ ë°˜í™˜      â”‚ â†’ JSON Response
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
Frontend (ê²°ê³¼ ì‹œê°í™”)
```

---

## 3. ë°ì´í„° íŒŒì´í”„ë¼ì¸

### 3.1 ê²½ê¸°ë„ ê¸°í›„í”Œë«í¼ ë°ì´í„° ìˆ˜ì§‘

```python
# data_collectors/climate_collector.py
import asyncio
import aiohttp
from datetime import datetime, timedelta
from typing import Dict, List

class ClimateDataCollector:
    """ê²½ê¸°ë„ ê¸°í›„í”Œë«í¼ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    BASE_URL = "https://climate.gg.go.kr/api"
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.session = None
    
    async def fetch_solar_radiation(
        self, 
        lat: float, 
        lon: float, 
        start_date: datetime,
        end_date: datetime
    ) -> Dict:
        """
        ì¼ì‚¬ëŸ‰ ë°ì´í„° ìˆ˜ì§‘
        
        Returns:
            {
                "location": {"lat": 37.xxx, "lon": 127.xxx},
                "period": {"start": "2024-01-01", "end": "2024-12-31"},
                "data": [
                    {
                        "date": "2024-01-01",
                        "solar_radiation": 3.5,  # kWh/mÂ²/day
                        "sunshine_hours": 5.2,   # hours
                        "cloud_cover": 30        # %
                    },
                    ...
                ]
            }
        """
        endpoint = f"{self.BASE_URL}/solar-radiation"
        params = {
            "lat": lat,
            "lon": lon,
            "start_date": start_date.strftime("%Y-%m-%d"),
            "end_date": end_date.strftime("%Y-%m-%d"),
            "api_key": self.api_key
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(endpoint, params=params) as response:
                return await response.json()
    
    async def fetch_weather_data(
        self, 
        lat: float, 
        lon: float,
        year: int
    ) -> Dict:
        """
        ê¸°ìƒ ë°ì´í„° ìˆ˜ì§‘ (ê¸°ì˜¨, ìŠµë„, ê°•ìˆ˜ëŸ‰)
        """
        endpoint = f"{self.BASE_URL}/weather"
        params = {
            "lat": lat,
            "lon": lon,
            "year": year,
            "api_key": self.api_key
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(endpoint, params=params) as response:
                return await response.json()
    
    async def get_historical_data(
        self,
        lat: float,
        lon: float,
        years: int = 5
    ) -> Dict:
        """
        ê³¼ê±° Në…„ ë°ì´í„° ìˆ˜ì§‘ (AI í•™ìŠµìš©)
        """
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365 * years)
        
        tasks = [
            self.fetch_solar_radiation(lat, lon, start_date, end_date),
            self.fetch_weather_data(lat, lon, end_date.year)
        ]
        
        results = await asyncio.gather(*tasks)
        return {
            "solar_radiation": results[0],
            "weather": results[1]
        }
```

### 3.2 ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```python
# data_collectors/preprocessor.py
import pandas as pd
import numpy as np
from typing import Dict, List

class DataPreprocessor:
    """ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§"""
    
    def preprocess_climate_data(self, raw_data: Dict) -> pd.DataFrame:
        """
        ê¸°í›„ ë°ì´í„° ì „ì²˜ë¦¬
        """
        df = pd.DataFrame(raw_data['data'])
        
        # ë‚ ì§œ íŒŒì‹±
        df['date'] = pd.to_datetime(df['date'])
        df['year'] = df['date'].dt.year
        df['month'] = df['date'].dt.month
        df['day_of_year'] = df['date'].dt.dayofyear
        
        # ê³„ì ˆ íŠ¹ì„±
        df['season'] = df['month'].apply(self._get_season)
        
        # ì´ë™ í‰ê·  (7ì¼, 30ì¼)
        df['solar_radiation_7d_ma'] = df['solar_radiation'].rolling(7).mean()
        df['solar_radiation_30d_ma'] = df['solar_radiation'].rolling(30).mean()
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = df.fillna(method='ffill').fillna(method='bfill')
        
        return df
    
    @staticmethod
    def _get_season(month: int) -> str:
        """ì›” â†’ ê³„ì ˆ ë³€í™˜"""
        if month in [3, 4, 5]:
            return 'spring'
        elif month in [6, 7, 8]:
            return 'summer'
        elif month in [9, 10, 11]:
            return 'fall'
        else:
            return 'winter'
    
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        AI ëª¨ë¸ í•™ìŠµìš© íŠ¹ì„± ìƒì„±
        """
        features = df.copy()
        
        # ì‹œê°„ íŠ¹ì„±
        features['sin_day_of_year'] = np.sin(2 * np.pi * features['day_of_year'] / 365)
        features['cos_day_of_year'] = np.cos(2 * np.pi * features['day_of_year'] / 365)
        
        # ì§€ì—° íŠ¹ì„± (ì „ë‚ , ì „ì£¼)
        features['solar_radiation_lag1'] = features['solar_radiation'].shift(1)
        features['solar_radiation_lag7'] = features['solar_radiation'].shift(7)
        
        # í†µê³„ íŠ¹ì„±
        features['solar_radiation_std_7d'] = features['solar_radiation'].rolling(7).std()
        features['solar_radiation_max_7d'] = features['solar_radiation'].rolling(7).max()
        features['solar_radiation_min_7d'] = features['solar_radiation'].rolling(7).min()
        
        return features.dropna()
```

### 3.3 ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

```sql
-- PostgreSQL + PostGIS ìŠ¤í‚¤ë§ˆ

-- ì‚¬ìš©ì í…Œì´ë¸”
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    name VARCHAR(100),
    phone VARCHAR(20),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ë¶„ì„ ìš”ì²­ í…Œì´ë¸”
CREATE TABLE analysis_requests (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    address TEXT NOT NULL,
    location GEOGRAPHY(POINT, 4326) NOT NULL,  -- PostGIS
    status VARCHAR(20) DEFAULT 'pending',  -- pending, processing, completed, failed
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP,
    
    -- ì¸ë±ìŠ¤
    INDEX idx_user_id (user_id),
    INDEX idx_status (status),
    INDEX idx_location USING GIST (location)
);

-- ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”
CREATE TABLE analysis_results (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    request_id UUID REFERENCES analysis_requests(id) ON DELETE CASCADE,
    
    -- ì§€ë¶• ë¶„ì„ ê²°ê³¼
    roof_area FLOAT,  -- mÂ²
    roof_direction VARCHAR(10),  -- N, NE, E, SE, S, SW, W, NW
    roof_angle FLOAT,  -- degrees
    usable_area FLOAT,  -- mÂ² (ì¥ì• ë¬¼ ì œì™¸)
    
    -- íƒœì–‘ê´‘ ì‹œìŠ¤í…œ
    recommended_capacity FLOAT,  -- kW
    panel_count INTEGER,
    
    -- ë°œì „ëŸ‰ ì˜ˆì¸¡
    annual_generation FLOAT,  -- kWh/year
    monthly_generation JSONB,  -- {"1": 250, "2": 280, ...}
    
    -- ê²½ì œì„± ë¶„ì„
    installation_cost INTEGER,  -- ì›
    subsidy_amount INTEGER,  -- ì›
    net_cost INTEGER,  -- ì›
    annual_savings INTEGER,  -- ì›/year
    payback_period FLOAT,  -- years
    roi_20years INTEGER,  -- ì›
    
    -- í™˜ê²½ ê¸°ì—¬
    co2_reduction FLOAT,  -- tons/year
    tree_equivalent INTEGER,  -- trees
    
    -- AI ì‹ ë¢°ë„
    prediction_confidence FLOAT,  -- 0-1
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ê¸°í›„ ë°ì´í„° ìºì‹œ í…Œì´ë¸”
CREATE TABLE climate_data_cache (
    id SERIAL PRIMARY KEY,
    location GEOGRAPHY(POINT, 4326) NOT NULL,
    year INTEGER NOT NULL,
    month INTEGER NOT NULL,
    
    solar_radiation FLOAT,  -- kWh/mÂ²/day
    temperature FLOAT,  -- Â°C
    humidity FLOAT,  -- %
    precipitation FLOAT,  -- mm
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE (location, year, month),
    INDEX idx_location_year USING GIST (location)
);

-- í”„ë¦¬ë¯¸ì—„ ë¦¬í¬íŠ¸ í…Œì´ë¸”
CREATE TABLE premium_reports (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    result_id UUID REFERENCES analysis_results(id),
    user_id UUID REFERENCES users(id),
    
    pdf_url TEXT,
    payment_id VARCHAR(100),
    amount INTEGER,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- B2B íŒŒíŠ¸ë„ˆ í…Œì´ë¸”
CREATE TABLE partners (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_name VARCHAR(200) NOT NULL,
    business_type VARCHAR(50),  -- realtor, installer
    subscription_plan VARCHAR(20),  -- basic, pro, enterprise
    api_key VARCHAR(100) UNIQUE,
    
    monthly_quota INTEGER,
    used_quota INTEGER DEFAULT 0,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## 4. AI ëª¨ë¸ ì„¤ê³„

### 4.1 íƒœì–‘ê´‘ ë°œì „ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸

#### ëª¨ë¸ 1: XGBoost Regressor

```python
# models/training/solar_prediction_model.py
import xgboost as xgb
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib

class SolarPowerPredictor:
    """íƒœì–‘ê´‘ ë°œì „ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self):
        self.model = None
        self.feature_names = None
        
    def train(self, X: pd.DataFrame, y: pd.Series):
        """
        ëª¨ë¸ í•™ìŠµ
        
        Features:
            - solar_radiation: ì¼ì‚¬ëŸ‰ (kWh/mÂ²/day)
            - temperature: ê¸°ì˜¨ (Â°C)
            - humidity: ìŠµë„ (%)
            - cloud_cover: ìš´ëŸ‰ (%)
            - roof_angle: ì§€ë¶• ê²½ì‚¬ê° (degrees)
            - roof_direction_encoded: ì§€ë¶• ë°©í–¥ (0-7)
            - panel_efficiency: íŒ¨ë„ íš¨ìœ¨ (%)
            - system_capacity: ì‹œìŠ¤í…œ ìš©ëŸ‰ (kW)
            - month: ì›” (1-12)
            - season_encoded: ê³„ì ˆ (0-3)
            - sin_day_of_year: ì—°ì¤‘ ì¼ìˆ˜ sin ë³€í™˜
            - cos_day_of_year: ì—°ì¤‘ ì¼ìˆ˜ cos ë³€í™˜
        
        Target:
            - daily_generation: ì¼ì¼ ë°œì „ëŸ‰ (kWh)
        """
        self.feature_names = X.columns.tolist()
        
        # Train/Test Split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # XGBoost íŒŒë¼ë¯¸í„°
        params = {
            'objective': 'reg:squarederror',
            'max_depth': 6,
            'learning_rate': 0.05,
            'n_estimators': 500,
            'min_child_weight': 3,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'gamma': 0.1,
            'reg_alpha': 0.1,
            'reg_lambda': 1.0,
            'random_state': 42
        }
        
        # ëª¨ë¸ í•™ìŠµ
        self.model = xgb.XGBRegressor(**params)
        self.model.fit(
            X_train, y_train,
            eval_set=[(X_test, y_test)],
            early_stopping_rounds=50,
            verbose=False
        )
        
        # í‰ê°€
        y_pred = self.model.predict(X_test)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        print(f"Model Performance:")
        print(f"  RMSE: {rmse:.4f} kWh")
        print(f"  MAE: {mae:.4f} kWh")
        print(f"  RÂ²: {r2:.4f}")
        
        # íŠ¹ì„± ì¤‘ìš”ë„
        feature_importance = pd.DataFrame({
            'feature': self.feature_names,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\nTop 10 Feature Importance:")
        print(feature_importance.head(10))
        
        return {
            'rmse': rmse,
            'mae': mae,
            'r2': r2,
            'feature_importance': feature_importance
        }
    
    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """ë°œì „ëŸ‰ ì˜ˆì¸¡"""
        if self.model is None:
            raise ValueError("Model not trained yet")
        
        return self.model.predict(X)
    
    def predict_monthly(
        self,
        solar_radiation_monthly: List[float],
        temperature_monthly: List[float],
        system_capacity: float,
        roof_angle: float,
        roof_direction: str,
        panel_efficiency: float = 0.18
    ) -> Dict:
        """
        ì›”ë³„ ë°œì „ëŸ‰ ì˜ˆì¸¡
        
        Returns:
            {
                "monthly": [250, 280, 320, ...],  # 12ê°œì›”
                "annual": 3650,
                "daily_average": 10.0
            }
        """
        monthly_predictions = []
        
        direction_map = {
            'S': 0, 'SE': 1, 'SW': 2, 'E': 3,
            'W': 4, 'NE': 5, 'NW': 6, 'N': 7
        }
        
        for month in range(1, 13):
            # íŠ¹ì„± ìƒì„±
            features = pd.DataFrame([{
                'solar_radiation': solar_radiation_monthly[month - 1],
                'temperature': temperature_monthly[month - 1],
                'humidity': 65,  # í‰ê· ê°’
                'cloud_cover': 40,  # í‰ê· ê°’
                'roof_angle': roof_angle,
                'roof_direction_encoded': direction_map.get(roof_direction, 0),
                'panel_efficiency': panel_efficiency,
                'system_capacity': system_capacity,
                'month': month,
                'season_encoded': (month - 1) // 3,
                'sin_day_of_year': np.sin(2 * np.pi * (month * 30) / 365),
                'cos_day_of_year': np.cos(2 * np.pi * (month * 30) / 365)
            }])
            
            # ì¼ì¼ ë°œì „ëŸ‰ ì˜ˆì¸¡
            daily_gen = self.predict(features)[0]
            
            # ì›”ë³„ ë°œì „ëŸ‰ (ì¼ì¼ Ã— í•´ë‹¹ ì›” ì¼ìˆ˜)
            days_in_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]
            monthly_gen = daily_gen * days_in_month[month - 1]
            monthly_predictions.append(round(monthly_gen, 2))
        
        annual_generation = sum(monthly_predictions)
        
        return {
            'monthly': monthly_predictions,
            'annual': round(annual_generation, 2),
            'daily_average': round(annual_generation / 365, 2)
        }
    
    def save(self, path: str):
        """ëª¨ë¸ ì €ì¥"""
        joblib.dump({
            'model': self.model,
            'feature_names': self.feature_names
        }, path)
        print(f"Model saved to {path}")
    
    @classmethod
    def load(cls, path: str):
        """ëª¨ë¸ ë¡œë“œ"""
        data = joblib.load(path)
        instance = cls()
        instance.model = data['model']
        instance.feature_names = data['feature_names']
        return instance
```

#### ëª¨ë¸ 2: LSTM (ì‹œê³„ì—´ ì˜ˆì¸¡)

```python
# models/training/lstm_model.py
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np

class LSTMSolarPredictor:
    """LSTM ê¸°ë°˜ ì‹œê³„ì—´ ë°œì „ëŸ‰ ì˜ˆì¸¡"""
    
    def __init__(self, sequence_length=30):
        self.sequence_length = sequence_length
        self.model = None
        self.scaler = None
    
    def build_model(self, n_features):
        """LSTM ëª¨ë¸ êµ¬ì¶•"""
        model = keras.Sequential([
            layers.LSTM(128, return_sequences=True, input_shape=(self.sequence_length, n_features)),
            layers.Dropout(0.2),
            layers.LSTM(64, return_sequences=False),
            layers.Dropout(0.2),
            layers.Dense(32, activation='relu'),
            layers.Dense(1)
        ])
        
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        
        self.model = model
        return model
    
    def prepare_sequences(self, data, target):
        """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±"""
        X, y = [], []
        
        for i in range(len(data) - self.sequence_length):
            X.append(data[i:i + self.sequence_length])
            y.append(target[i + self.sequence_length])
        
        return np.array(X), np.array(y)
```

### 4.2 ì§€ë¶• ë¶„ì„ Computer Vision ëª¨ë¸

```python
# models/training/roof_analysis_model.py
import cv2
import numpy as np
from PIL import Image
import rasterio
from rasterio.features import shapes
from shapely.geometry import shape, Polygon
import math

class RoofAnalyzer:
    """ìœ„ì„± ì´ë¯¸ì§€ ê¸°ë°˜ ì§€ë¶• ë¶„ì„"""
    
    def __init__(self):
        self.min_roof_area = 20  # mÂ²
    
    def analyze_roof(self, satellite_image_path: str, lat: float, lon: float) -> Dict:
        """
        ìœ„ì„± ì´ë¯¸ì§€ì—ì„œ ì§€ë¶• ë¶„ì„
        
        Returns:
            {
                "roof_area": 150.5,  # mÂ²
                "roof_direction": "S",  # ì£¼ ë°©í–¥
                "roof_angle": 25.0,  # degrees
                "usable_area": 135.0,  # mÂ² (ì¥ì• ë¬¼ ì œì™¸)
                "obstacles": [
                    {"type": "chimney", "area": 2.5},
                    {"type": "skylight", "area": 5.0}
                ],
                "optimal_panel_layout": {
                    "rows": 6,
                    "columns": 10,
                    "panel_count": 60,
                    "total_capacity": 18.0  # kW
                }
            }
        """
        # ì´ë¯¸ì§€ ë¡œë“œ
        img = cv2.imread(satellite_image_path)
        
        # ì§€ë¶• ì˜ì—­ ê°ì§€
        roof_mask = self._detect_roof(img)
        
        # ì§€ë¶• ë©´ì  ê³„ì‚°
        roof_area = self._calculate_area(roof_mask, lat, lon)
        
        # ì§€ë¶• ë°©í–¥ ì¶”ì •
        roof_direction = self._estimate_direction(roof_mask)
        
        # ì§€ë¶• ê²½ì‚¬ê° ì¶”ì • (ê·¸ë¦¼ì ë¶„ì„)
        roof_angle = self._estimate_angle(img, roof_mask)
        
        # ì¥ì• ë¬¼ ê°ì§€
        obstacles = self._detect_obstacles(img, roof_mask)
        
        # ì‚¬ìš© ê°€ëŠ¥ ë©´ì  ê³„ì‚°
        usable_area = roof_area - sum(obs['area'] for obs in obstacles)
        
        # ìµœì  íŒ¨ë„ ë°°ì¹˜
        panel_layout = self._optimize_panel_layout(usable_area, roof_direction)
        
        return {
            'roof_area': round(roof_area, 2),
            'roof_direction': roof_direction,
            'roof_angle': round(roof_angle, 1),
            'usable_area': round(usable_area, 2),
            'obstacles': obstacles,
            'optimal_panel_layout': panel_layout
        }
    
    def _detect_roof(self, img: np.ndarray) -> np.ndarray:
        """ì§€ë¶• ì˜ì—­ ê°ì§€ (ê°„ë‹¨í•œ ë²„ì „)"""
        # ì‹¤ì œë¡œëŠ” Mask R-CNN ë“± ì‚¬ìš©
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
        
        # ìœ¤ê³½ì„  ì°¾ê¸°
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # ê°€ì¥ í° ìœ¤ê³½ì„  = ì§€ë¶•
        if contours:
            largest_contour = max(contours, key=cv2.contourArea)
            mask = np.zeros_like(gray)
            cv2.drawContours(mask, [largest_contour], 0, 255, -1)
            return mask
        
        return np.zeros_like(gray)
    
    def _calculate_area(self, mask: np.ndarray, lat: float, lon: float) -> float:
        """ë§ˆìŠ¤í¬ì—ì„œ ì‹¤ì œ ë©´ì  ê³„ì‚° (mÂ²)"""
        pixel_count = np.sum(mask > 0)
        
        # ìœ„ë„ì— ë”°ë¥¸ í”½ì…€ë‹¹ ë¯¸í„° ê³„ì‚°
        # (ê°„ë‹¨í•œ ê·¼ì‚¬ì‹, ì‹¤ì œë¡œëŠ” ë” ì •í™•í•œ ê³„ì‚° í•„ìš”)
        meters_per_pixel = 0.3  # ìœ„ì„± ì´ë¯¸ì§€ í•´ìƒë„ì— ë”°ë¼ ì¡°ì •
        
        area_m2 = pixel_count * (meters_per_pixel ** 2)
        return area_m2
    
    def _estimate_direction(self, mask: np.ndarray) -> str:
        """ì§€ë¶• ì£¼ ë°©í–¥ ì¶”ì •"""
        # ìœ¤ê³½ì„ ì˜ ìµœì†Œ ë©´ì  ì§ì‚¬ê°í˜• ì°¾ê¸°
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            return 'S'  # ê¸°ë³¸ê°’
        
        largest_contour = max(contours, key=cv2.contourArea)
        rect = cv2.minAreaRect(largest_contour)
        angle = rect[2]
        
        # ê°ë„ë¥¼ ë°©í–¥ìœ¼ë¡œ ë³€í™˜
        if -22.5 <= angle < 22.5:
            return 'S'
        elif 22.5 <= angle < 67.5:
            return 'SE'
        elif 67.5 <= angle < 112.5:
            return 'E'
        elif 112.5 <= angle < 157.5:
            return 'NE'
        else:
            return 'N'
    
    def _estimate_angle(self, img: np.ndarray, mask: np.ndarray) -> float:
        """ì§€ë¶• ê²½ì‚¬ê° ì¶”ì • (ê·¸ë¦¼ì ë¶„ì„)"""
        # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ í•„ìš”
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ í‰ê· ê°’ ë°˜í™˜
        return 25.0  # degrees
    
    def _detect_obstacles(self, img: np.ndarray, roof_mask: np.ndarray) -> List[Dict]:
        """ì§€ë¶• ìœ„ ì¥ì• ë¬¼ ê°ì§€ (êµ´ëš, ì²œì°½ ë“±)"""
        # ì‹¤ì œë¡œëŠ” object detection ëª¨ë¸ ì‚¬ìš©
        obstacles = []
        
        # ê°„ë‹¨í•œ ì˜ˆì‹œ
        # ... (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
        
        return obstacles
    
    def _optimize_panel_layout(self, usable_area: float, direction: str) -> Dict:
        """ìµœì  íŒ¨ë„ ë°°ì¹˜ ê³„ì‚°"""
        # í‘œì¤€ íŒ¨ë„ í¬ê¸°: 1.6m Ã— 1.0m = 1.6mÂ²
        panel_area = 1.6
        panel_power = 300  # W
        
        # ì„¤ì¹˜ ê°„ê²© ê³ ë ¤ (íŒ¨ë„ ì‚¬ì´ 0.1m)
        effective_panel_area = 1.8  # mÂ² (ê°„ê²© í¬í•¨)
        
        # ì„¤ì¹˜ ê°€ëŠ¥ íŒ¨ë„ ìˆ˜
        panel_count = int(usable_area / effective_panel_area)
        
        # í–‰/ì—´ ê³„ì‚° (ìµœì í™”)
        rows = int(np.sqrt(panel_count * 0.6))
        columns = int(panel_count / rows)
        
        total_capacity = (panel_count * panel_power) / 1000  # kW
        
        return {
            'rows': rows,
            'columns': columns,
            'panel_count': panel_count,
            'total_capacity': round(total_capacity, 2)
        }
```

---

## 5. API ì„¤ê³„

### 5.1 RESTful API ì—”ë“œí¬ì¸íŠ¸

```python
# backend/api/main.py
from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Optional, List
import uuid

app = FastAPI(
    title="SolarScan API",
    description="AI ê¸°ë°˜ íƒœì–‘ê´‘ ì„¤ì¹˜ ë¶„ì„ API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://solarscan.kr", "http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Request/Response ëª¨ë¸
class AnalysisRequest(BaseModel):
    address: str = Field(..., description="ë¶„ì„í•  ì£¼ì†Œ", example="ê²½ê¸°ë„ ìˆ˜ì›ì‹œ ì˜í†µêµ¬ ê´‘êµë¡œ 156")
    building_type: str = Field("house", description="ê±´ë¬¼ ìœ í˜•", example="house")  # house, apartment
    email: Optional[str] = Field(None, description="ê²°ê³¼ ìˆ˜ì‹  ì´ë©”ì¼")

class AnalysisResponse(BaseModel):
    request_id: str
    status: str  # pending, processing, completed, failed
    message: str

class ResultResponse(BaseModel):
    request_id: str
    address: str
    location: dict
    
    roof_analysis: dict
    solar_prediction: dict
    economic_analysis: dict
    environmental_impact: dict
    
    confidence_score: float
    created_at: str

# API ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/v1/analysis", response_model=AnalysisResponse)
async def create_analysis(
    request: AnalysisRequest,
    background_tasks: BackgroundTasks
):
    """
    íƒœì–‘ê´‘ ì„¤ì¹˜ ë¶„ì„ ìš”ì²­
    
    - **address**: ë¶„ì„í•  ì£¼ì†Œ (í•„ìˆ˜)
    - **building_type**: ê±´ë¬¼ ìœ í˜• (house, apartment)
    - **email**: ê²°ê³¼ ìˆ˜ì‹  ì´ë©”ì¼ (ì„ íƒ)
    
    Returns:
        - request_id: ë¶„ì„ ìš”ì²­ ID
        - status: ì²˜ë¦¬ ìƒíƒœ
    """
    # ì£¼ì†Œ ê²€ì¦
    geocode_result = await geocode_address(request.address)
    if not geocode_result:
        raise HTTPException(status_code=400, detail="Invalid address")
    
    # ìš”ì²­ ID ìƒì„±
    request_id = str(uuid.uuid4())
    
    # ë¹„ë™ê¸° ë¶„ì„ ì‘ì—… ì‹œì‘
    background_tasks.add_task(
        process_analysis,
        request_id=request_id,
        address=request.address,
        location=geocode_result,
        building_type=request.building_type,
        email=request.email
    )
    
    return AnalysisResponse(
        request_id=request_id,
        status="processing",
        message="ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì•½ 30ì´ˆ ì†Œìš”ë©ë‹ˆë‹¤."
    )

@app.get("/api/v1/analysis/{request_id}", response_model=ResultResponse)
async def get_analysis_result(request_id: str):
    """
    ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
    
    - **request_id**: ë¶„ì„ ìš”ì²­ ID
    
    Returns:
        - ë¶„ì„ ì™„ë£Œ ì‹œ: ì „ì²´ ê²°ê³¼
        - ë¶„ì„ ì¤‘: status = processing
        - ì‹¤íŒ¨: status = failed
    """
    result = await get_result_from_db(request_id)
    
    if not result:
        raise HTTPException(status_code=404, detail="Analysis not found")
    
    return result

@app.get("/api/v1/heatmap")
async def get_solar_heatmap(
    region: str = "gyeonggi",
    metric: str = "solar_radiation"
):
    """
    ê²½ê¸°ë„ ì¼ì‚¬ëŸ‰ íˆíŠ¸ë§µ ë°ì´í„°
    
    - **region**: ì§€ì—­ (gyeonggi, seoul, etc.)
    - **metric**: ì§€í‘œ (solar_radiation, cost_savings, roi)
    
    Returns:
        - GeoJSON í˜•ì‹ì˜ íˆíŠ¸ë§µ ë°ì´í„°
    """
    heatmap_data = await generate_heatmap(region, metric)
    return heatmap_data

@app.post("/api/v1/compare")
async def compare_locations(addresses: List[str]):
    """
    ì—¬ëŸ¬ ì£¼ì†Œ ë¹„êµ ë¶„ì„
    
    - **addresses**: ë¹„êµí•  ì£¼ì†Œ ëª©ë¡ (ìµœëŒ€ 5ê°œ)
    
    Returns:
        - ê° ì£¼ì†Œë³„ ë¶„ì„ ê²°ê³¼ ë° ë¹„êµ ì°¨íŠ¸ ë°ì´í„°
    """
    if len(addresses) > 5:
        raise HTTPException(status_code=400, detail="Maximum 5 addresses allowed")
    
    results = []
    for address in addresses:
        result = await quick_analysis(address)
        results.append(result)
    
    comparison = generate_comparison(results)
    return comparison

# B2B API
@app.post("/api/v1/partner/batch-analysis")
async def batch_analysis(
    addresses: List[str],
    api_key: str = Depends(verify_api_key)
):
    """
    B2B íŒŒíŠ¸ë„ˆìš© ë°°ì¹˜ ë¶„ì„
    
    - **addresses**: ë¶„ì„í•  ì£¼ì†Œ ëª©ë¡
    - **api_key**: íŒŒíŠ¸ë„ˆ API í‚¤ (í—¤ë”)
    
    Returns:
        - ë°°ì¹˜ ì‘ì—… ID ë° ê° ì£¼ì†Œë³„ request_id
    """
    batch_id = str(uuid.uuid4())
    request_ids = []
    
    for address in addresses:
        request_id = await create_analysis_task(address, batch_id)
        request_ids.append(request_id)
    
    return {
        "batch_id": batch_id,
        "request_ids": request_ids,
        "total_count": len(addresses)
    }
```

### 5.2 WebSocket API (ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©)

```python
# backend/api/websocket.py
from fastapi import WebSocket, WebSocketDisconnect
from typing import Dict
import json

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
    
    async def connect(self, request_id: str, websocket: WebSocket):
        await websocket.accept()
        self.active_connections[request_id] = websocket
    
    def disconnect(self, request_id: str):
        if request_id in self.active_connections:
            del self.active_connections[request_id]
    
    async def send_progress(self, request_id: str, message: dict):
        if request_id in self.active_connections:
            await self.active_connections[request_id].send_json(message)

manager = ConnectionManager()

@app.websocket("/ws/analysis/{request_id}")
async def websocket_endpoint(websocket: WebSocket, request_id: str):
    await manager.connect(request_id, websocket)
    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹  (keep-alive)
            data = await websocket.receive_text()
            
            # ì§„í–‰ ìƒí™© ì „ì†¡
            await manager.send_progress(request_id, {
                "status": "processing",
                "progress": 50,
                "message": "AI ëª¨ë¸ ë¶„ì„ ì¤‘..."
            })
    except WebSocketDisconnect:
        manager.disconnect(request_id)
```

---

## 6. í”„ë¡ íŠ¸ì—”ë“œ ì•„í‚¤í…ì²˜

### 6.1 Next.js í”„ë¡œì íŠ¸ êµ¬ì¡°

```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â”œâ”€â”€ page.tsx (í™ˆí˜ì´ì§€)
â”‚   â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”‚   â””â”€â”€ [id]/
â”‚   â”‚   â”‚       â””â”€â”€ page.tsx (ê²°ê³¼ í˜ì´ì§€)
â”‚   â”‚   â”œâ”€â”€ compare/
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx (ë¹„êµ í˜ì´ì§€)
â”‚   â”‚   â”œâ”€â”€ heatmap/
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx (íˆíŠ¸ë§µ í˜ì´ì§€)
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â””â”€â”€ [...]/route.ts (API Routes)
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”‚   â”œâ”€â”€ Button.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Input.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Card.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”‚   â”œâ”€â”€ AddressSearch.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ResultDashboard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ RoofVisualization.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ PowerChart.tsx
â”‚   â”‚   â”‚   â””â”€â”€ CostBreakdown.tsx
â”‚   â”‚   â”œâ”€â”€ map/
â”‚   â”‚   â”‚   â”œâ”€â”€ KakaoMap.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Heatmap.tsx
â”‚   â”‚   â””â”€â”€ layout/
â”‚   â”‚       â”œâ”€â”€ Header.tsx
â”‚   â”‚       â”œâ”€â”€ Footer.tsx
â”‚   â”‚       â””â”€â”€ Sidebar.tsx
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ api.ts (API í´ë¼ì´ì–¸íŠ¸)
â”‚   â”‚   â”œâ”€â”€ websocket.ts
â”‚   â”‚   â””â”€â”€ analytics.ts
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useAnalysis.ts
â”‚   â”‚   â”œâ”€â”€ useWebSocket.ts
â”‚   â”‚   â””â”€â”€ useMap.ts
â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â”œâ”€â”€ analysisStore.ts (Zustand)
â”‚   â”‚   â””â”€â”€ userStore.ts
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ formatters.ts
â”‚   â”‚   â”œâ”€â”€ validators.ts
â”‚   â”‚   â””â”€â”€ constants.ts
â”‚   â””â”€â”€ types/
â”‚       â”œâ”€â”€ analysis.ts
â”‚       â”œâ”€â”€ api.ts
â”‚       â””â”€â”€ map.ts
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ icons/
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ tailwind.config.js
â””â”€â”€ next.config.js
```

### 6.2 í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì˜ˆì‹œ

```typescript
// src/components/analysis/AddressSearch.tsx
'use client';

import { useState } from 'react';
import { useRouter } from 'next/navigation';
import { Button } from '@/components/ui/Button';
import { Input } from '@/components/ui/Input';
import { createAnalysis } from '@/services/api';

export function AddressSearch() {
  const [address, setAddress] = useState('');
  const [loading, setLoading] = useState(false);
  const router = useRouter();

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setLoading(true);

    try {
      const result = await createAnalysis({ address });
      router.push(`/analysis/${result.request_id}`);
    } catch (error) {
      console.error('Analysis failed:', error);
      alert('ë¶„ì„ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setLoading(false);
    }
  };

  return (
    <form onSubmit={handleSubmit} className="max-w-2xl mx-auto">
      <div className="flex gap-4">
        <Input
          type="text"
          value={address}
          onChange={(e) => setAddress(e.target.value)}
          placeholder="ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ê²½ê¸°ë„ ìˆ˜ì›ì‹œ ì˜í†µêµ¬ ê´‘êµë¡œ 156)"
          className="flex-1"
          required
        />
        <Button type="submit" loading={loading}>
          ë¶„ì„ ì‹œì‘
        </Button>
      </div>
    </form>
  );
}
```

```typescript
// src/hooks/useAnalysis.ts
import { useState, useEffect } from 'react';
import { getAnalysisResult } from '@/services/api';
import { useWebSocket } from './useWebSocket';
import type { AnalysisResult } from '@/types/analysis';

export function useAnalysis(requestId: string) {
  const [result, setResult] = useState<AnalysisResult | null>(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const [progress, setProgress] = useState(0);

  // WebSocketìœ¼ë¡œ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ìˆ˜ì‹ 
  const { message } = useWebSocket(`/ws/analysis/${requestId}`);

  useEffect(() => {
    if (message) {
      setProgress(message.progress);
    }
  }, [message]);

  useEffect(() => {
    const fetchResult = async () => {
      try {
        const data = await getAnalysisResult(requestId);
        
        if (data.status === 'completed') {
          setResult(data);
          setLoading(false);
        } else if (data.status === 'failed') {
          setError('ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
          setLoading(false);
        } else {
          // ì•„ì§ ì²˜ë¦¬ ì¤‘ì´ë©´ 3ì´ˆ í›„ ì¬ì‹œë„
          setTimeout(fetchResult, 3000);
        }
      } catch (err) {
        setError('ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
        setLoading(false);
      }
    };

    fetchResult();
  }, [requestId]);

  return { result, loading, error, progress };
}
```

---

## 7. ì¸í”„ë¼ ë° ë°°í¬

### 7.1 Docker êµ¬ì„±

```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    gdal-bin \
    libgdal-dev \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# Uvicorn ì„œë²„ ì‹¤í–‰
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Backend API
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/solarscan
      - REDIS_URL=redis://redis:6379/0
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    depends_on:
      - db
      - redis
    volumes:
      - ./backend:/app
      - ./data:/data
      - ./models:/models

  # Celery Worker
  celery:
    build: ./backend
    command: celery -A services.celery_app worker --loglevel=info
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/solarscan
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
      - rabbitmq
    volumes:
      - ./backend:/app
      - ./data:/data
      - ./models:/models

  # PostgreSQL
  db:
    image: postgis/postgis:15-3.3
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=solarscan
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # Redis
  redis:
    image: redis:7.2-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  # RabbitMQ
  rabbitmq:
    image: rabbitmq:3.12-management
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=password

  # Nginx (Reverse Proxy)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - backend

volumes:
  postgres_data:
  redis_data:
```

### 7.2 CI/CD íŒŒì´í”„ë¼ì¸

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-cov
      
      - name: Run tests
        run: |
          cd backend
          pytest tests/ --cov=. --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3

  deploy-backend:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-2
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1
      
      - name: Build and push Docker image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: solarscan-backend
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG ./backend
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
      
      - name: Deploy to ECS
        run: |
          aws ecs update-service \
            --cluster solarscan-cluster \
            --service solarscan-backend \
            --force-new-deployment

  deploy-frontend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: |
          cd frontend
          npm ci
      
      - name: Build
        run: |
          cd frontend
          npm run build
        env:
          NEXT_PUBLIC_API_URL: ${{ secrets.API_URL }}
      
      - name: Deploy to Vercel
        uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
          vercel-args: '--prod'
          working-directory: ./frontend
```

---

## 8. ë³´ì•ˆ ë° ì„±ëŠ¥

### 8.1 ë³´ì•ˆ ì¡°ì¹˜

```python
# backend/utils/security.py
from fastapi import Security, HTTPException, status
from fastapi.security import APIKeyHeader
from passlib.context import CryptContext
import jwt
from datetime import datetime, timedelta

# ë¹„ë°€ë²ˆí˜¸ í•´ì‹±
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# API í‚¤ ì¸ì¦
api_key_header = APIKeyHeader(name="X-API-Key")

async def verify_api_key(api_key: str = Security(api_key_header)):
    """B2B íŒŒíŠ¸ë„ˆ API í‚¤ ê²€ì¦"""
    partner = await get_partner_by_api_key(api_key)
    
    if not partner:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Invalid API key"
        )
    
    # í• ë‹¹ëŸ‰ í™•ì¸
    if partner.used_quota >= partner.monthly_quota:
        raise HTTPException(
            status_code=status.HTTP_429_TOO_MANY_REQUESTS,
            detail="API quota exceeded"
        )
    
    return partner

# JWT í† í°
SECRET_KEY = "your-secret-key-here"  # í™˜ê²½ ë³€ìˆ˜ë¡œ ê´€ë¦¬
ALGORITHM = "HS256"

def create_access_token(data: dict, expires_delta: timedelta = None):
    """JWT ì•¡ì„¸ìŠ¤ í† í° ìƒì„±"""
    to_encode = data.copy()
    expire = datetime.utcnow() + (expires_delta or timedelta(hours=24))
    to_encode.update({"exp": expire})
    
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

# Rate Limiting
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/api/v1/analysis")
@limiter.limit("10/minute")  # ë¶„ë‹¹ 10íšŒ ì œí•œ
async def create_analysis(request: Request, ...):
    ...
```

### 8.2 ì„±ëŠ¥ ìµœì í™”

```python
# backend/utils/cache.py
import redis
import json
from functools import wraps
from typing import Callable

redis_client = redis.Redis(host='redis', port=6379, db=0)

def cache_result(expire_seconds: int = 3600):
    """ê²°ê³¼ ìºì‹± ë°ì½”ë ˆì´í„°"""
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"{func.__name__}:{str(args)}:{str(kwargs)}"
            
            # ìºì‹œ í™•ì¸
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)
            
            # í•¨ìˆ˜ ì‹¤í–‰
            result = await func(*args, **kwargs)
            
            # ìºì‹œ ì €ì¥
            redis_client.setex(
                cache_key,
                expire_seconds,
                json.dumps(result)
            )
            
            return result
        return wrapper
    return decorator

# ì‚¬ìš© ì˜ˆì‹œ
@cache_result(expire_seconds=86400)  # 24ì‹œê°„ ìºì‹±
async def get_climate_data(lat: float, lon: float, year: int):
    # ê²½ê¸°ë„ ê¸°í›„í”Œë«í¼ API í˜¸ì¶œ
    ...
```

```python
# backend/utils/database.py
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

# ë¹„ë™ê¸° DB ì—”ì§„
engine = create_async_engine(
    "postgresql+asyncpg://user:password@db:5432/solarscan",
    echo=False,
    pool_size=20,
    max_overflow=40,
    pool_pre_ping=True
)

AsyncSessionLocal = sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False
)

# ì—°ê²° í’€ë§ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
```

---

## 9. ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

```python
# backend/utils/monitoring.py
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration
from sentry_sdk.integrations.celery import CeleryIntegration

# Sentry ì´ˆê¸°í™”
sentry_sdk.init(
    dsn="your-sentry-dsn",
    integrations=[
        FastApiIntegration(),
        CeleryIntegration()
    ],
    traces_sample_rate=0.1,
    profiles_sample_rate=0.1
)

# ë¡œê¹… ì„¤ì •
import logging
from pythonjsonlogger import jsonlogger

logger = logging.getLogger()
logHandler = logging.StreamHandler()
formatter = jsonlogger.JsonFormatter()
logHandler.setFormatter(formatter)
logger.addHandler(logHandler)
logger.setLevel(logging.INFO)
```

---

**ì‘ì„±ì¼**: 2025ë…„ 11ì›” 5ì¼  
**ë²„ì „**: 1.0  
**ì‘ì„±ì**: SolarScan ê¸°ìˆ íŒ€

